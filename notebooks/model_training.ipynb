{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\! Proyectos\\ML_number_class\\dataset\\data_v1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers will be converted to a binary representation. This can make the data more suitable for classification algorithms, since multiples of 3 and 5 can have recognizable patterns in their binary representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert numbers to their binary representation\n",
    "def binary_encode(i, num_digits):\n",
    "    return np.array([i >> d & 1 for d in range(num_digits)])\n",
    "\n",
    "# Number of digits in the binary representation (for 1000 we need 10 digits)\n",
    "num_digits = 10\n",
    "\n",
    "# Applying the binary encoding function to the 'Number' column\n",
    "binary_representation = df['Number'].apply(lambda x: binary_encode(x, num_digits))\n",
    "\n",
    "# Creating a DataFrame from the binary matrix\n",
    "binary_df_v1 = pd.DataFrame(binary_representation.tolist(), columns=[f'Bit_{i}' for i in range(num_digits)])\n",
    "\n",
    "# Concatenating the binary DataFrame with the original\n",
    "data_v1_transformed = pd.concat([df, binary_df_v1], axis=1)\n",
    "\n",
    "# Saving new data\n",
    "data_v1_transformed.to_csv(\"D:\\! Proyectos\\ML_number_class\\dataset\\data_v2.csv\", index = False)\n",
    "\n",
    "# Displaying the first rows of the transformed DataFrame\n",
    "data_v1_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base case will be established with the numbers directly and without cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Extracting training data (numbers from 101 to 1000)\n",
    "training_data = data_v1_transformed[df['Number'] > 100]\n",
    "\n",
    "# Extracting validation data (numbers from 1 to 100)\n",
    "validation_data = data_v1_transformed[df['Number'] <= 100]\n",
    "\n",
    "# Splitting the features and labels for training data\n",
    "X_train = training_data[['Number']]\n",
    "y_train = training_data['Label']\n",
    "\n",
    "# Splitting the features and labels for validation data\n",
    "X_test = validation_data[['Number']]\n",
    "y_test = validation_data['Label']\n",
    "\n",
    "# Label codification\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "trained_models = {}\n",
    "results = {}\n",
    "\n",
    "classifiers = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000)),\n",
    "    ('Support Vector Machine', SVC()),\n",
    "    ('Decision Tree', DecisionTreeClassifier()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('K-Neighbors', KNeighborsClassifier()),\n",
    "    ('XGBoost', XGBClassifier())\n",
    "]\n",
    "\n",
    "for name, clf in classifiers:\n",
    "    clf.fit(X_train, y_train_encoded)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test_encoded, y_pred)\n",
    "    results[name] = acc\n",
    "    \n",
    "    trained_models[name] = clf\n",
    "\n",
    "    print(f'{name}: {acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently the algorithms are not learning to classify the patterns of the data set. Specific predictions will be reviewed to investigate the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_encoded = trained_models['Logistic Regression'].predict(X_test)\n",
    "\n",
    "\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "\n",
    "predictions_vs_true = pd.DataFrame({'True Label': y_test, 'Predicted Label': y_pred})\n",
    "predictions_vs_true.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions reveal that the model is consistently predicting the class \"Non\" for all instances in the validation set. This explains why the precision is about 0.53, since the \"None\" class represents about 53% of the labels in the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the algorithms will be trained with the binary representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the new feature\n",
    "X_train = training_data[['Bit_0', 'Bit_1', 'Bit_2', 'Bit_3', 'Bit_4', 'Bit_5', 'Bit_6', 'Bit_7', 'Bit_8', 'Bit_9']]\n",
    "X_test = validation_data[['Bit_0', 'Bit_1', 'Bit_2', 'Bit_3', 'Bit_4', 'Bit_5', 'Bit_6', 'Bit_7', 'Bit_8', 'Bit_9']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models2 = {}\n",
    "results2 = {}\n",
    "\n",
    "for name, clf in classifiers:\n",
    "    clf.fit(X_train, y_train_encoded)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test_encoded, y_pred)\n",
    "    results2[name] = acc\n",
    "    \n",
    "    trained_models2[name] = clf\n",
    "\n",
    "    print(f'{name}: {acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_encoded = trained_models['Decision Tree'].predict(X_test)\n",
    "\n",
    "\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "\n",
    "predictions_vs_true = pd.DataFrame({'True Label': y_test, 'Predicted Label': y_pred})\n",
    "predictions_vs_true.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that some models began to learn relationships in the dataset but with very poor results. Let's perform a correlation study between the dependent variables and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "# Correcting the mapping for \"Non\" label\n",
    "label_encoding = {\"Non\": 0, \"Fizz\": 1, \"Buzz\": 2, \"FizzBuzz\": 3}\n",
    "data_v1_transformed['Label_encoded'] = data_v1_transformed['Label'].map(label_encoding)\n",
    "\n",
    "# Calculating the point biserial correlation again between the binary representation and the encoded label\n",
    "correlations_with_label_corrected = {col: pointbiserialr(data_v1_transformed[col], data_v1_transformed['Label_encoded']).correlation\n",
    "                                     for col in ['Number','Bit_0', 'Bit_1', 'Bit_2', 'Bit_3', 'Bit_4', 'Bit_5', 'Bit_6', 'Bit_7', 'Bit_8', 'Bit_9']}\n",
    "\n",
    "correlations_with_label_corrected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These low correlation values may explain why previously trained models did not perform well using these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since traditional classifiers are not learning the patterns in the data set, a neural network will be trained, specifically an MLP. Neural networks tend to learn numerical relationships well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"D:\\! Proyectos\\ML_number_class\\dataset\\data_v2.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extracting training data (numbers from 101 to 1000)\n",
    "training_data = df[df['Number'] > 100]\n",
    "\n",
    "# Extracting validation data (numbers from 1 to 100)\n",
    "validation_data = df[df['Number'] <= 100]\n",
    "\n",
    "# Splitting the features and labels for training data\n",
    "X_train = training_data[['Bit_0', 'Bit_1', 'Bit_2', 'Bit_3', 'Bit_4', 'Bit_5', 'Bit_6', 'Bit_7', 'Bit_8', 'Bit_9']]\n",
    "y_train = training_data['Label']\n",
    "\n",
    "# Splitting the features and labels for validation data\n",
    "X_test = validation_data[['Bit_0', 'Bit_1', 'Bit_2', 'Bit_3', 'Bit_4', 'Bit_5', 'Bit_6', 'Bit_7', 'Bit_8', 'Bit_9']]\n",
    "y_test = validation_data['Label']\n",
    "\n",
    "# Label codification\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MLP classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(200, 50), max_iter=10000, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp_clf.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Predict the labels for the validation data\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the MLP\n",
    "mlp_accuracy = accuracy_score(y_test_encoded, y_pred_mlp)\n",
    "\n",
    "print(f'MLP Accuracy: {mlp_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_encoded = mlp_clf.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "\n",
    "predictions_vs_true = pd.DataFrame({'True Label': y_test, 'Predicted Label': y_pred})\n",
    "predictions_vs_true.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have an acceptable model, so we will proceed to make the service app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "import pickle\n",
    "with open(r'D:\\! Proyectos\\ML_number_class\\artifacts\\model_mlp.pkl', 'wb') as file:\n",
    "    pickle.dump(mlp_clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
